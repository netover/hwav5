"""
Two-Phase Filtering Strategy for RAG Retrieval.

PR2: Implements "soft-then-hard" filtering to prevent the "filter kills recall" problem.

Based on IEEE paper "Two-Step RAG for Metadata Filtering" (2025):
- Phase 1: Broad semantic search with soft/inclusive filters
- Phase 2: Metadata refinement with strict filters
- Phase 3: Fallback if results < min_results

Key improvements:
- 2.51x accuracy improvement
- 18% reduction in hallucinations
- Prevents empty result sets

Author: Resync Team
Version: 5.7.0
"""

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from enum import Enum
from typing import Any

logger = logging.getLogger(__name__)


class FilterStrategy(str, Enum):
    """Available filtering strategies."""

    PRE_FILTER = "pre_filter"  # Filter before vector search (fast, may miss)
    POST_FILTER = "post_filter"  # Filter after vector search (slower, complete)
    TWO_PHASE = "two_phase"  # Best of both worlds (recommended)
    ADAPTIVE = "adaptive"  # Auto-select based on filter selectivity


@dataclass
class FilterConfig:
    """Configuration for metadata filtering."""

    strategy: FilterStrategy = FilterStrategy.TWO_PHASE

    # Phase 1: Soft filters (applied during vector search with OR logic)
    soft_filters: dict[str, Any] = field(default_factory=dict)

    # Phase 2: Hard filters (applied post-retrieval with AND logic)
    hard_filters: dict[str, Any] = field(default_factory=dict)

    # Fallback configuration
    enable_fallback: bool = True
    fallback_remove_filters: list[str] = field(
        default_factory=lambda: ["tags", "category", "doc_type", "platform", "environment"]
    )
    min_results: int = 3  # Trigger fallback if below this

    # Logging
    log_filtered_count: bool = True


@dataclass
class FilterResult:
    """Result of applying filters with diagnostics."""

    documents: list[dict[str, Any]]

    # Diagnostics
    phase1_count: int  # After soft filter
    phase2_count: int  # After hard filter
    filtered_out_count: int
    fallback_triggered: bool
    fallback_reason: str | None

    # For debugging
    filter_breakdown: dict[str, int] = field(default_factory=dict)


class TwoPhaseFilter:
    """
    Implements two-phase filtering to balance recall and precision.

    Architecture:
        1. Phase 1 (Soft): Apply inclusive filters during retrieval
           - Uses OR logic for multi-value fields
           - Includes "global" documents (platform=all)

        2. Phase 2 (Hard): Apply strict filters post-retrieval
           - Uses AND logic
           - Logs what was filtered out

        3. Fallback: If results < min_results
           - Progressively removes least important filters
           - Returns results with warning
    """

    # Hierarchical value mappings for normalization
    PLATFORM_HIERARCHY: dict[str, list[str]] = {
        "ios": ["ios", "mobile", "all"],
        "android": ["android", "mobile", "all"],
        "mobile": ["mobile", "all"],
        "web": ["web", "all"],
        "desktop": ["desktop", "all"],
        "all": ["all"],
    }

    ENVIRONMENT_HIERARCHY: dict[str, list[str]] = {
        "prod": ["prod", "production", "all"],
        "production": ["prod", "production", "all"],
        "staging": ["staging", "all"],
        "dev": ["dev", "development", "all"],
        "development": ["dev", "development", "all"],
        "all": ["all"],
    }

    def __init__(self, config: FilterConfig | None = None):
        self.config = config or FilterConfig()

    def normalize_filter_value(self, key: str, value: Any) -> list[Any]:
        """
        Normalize filter values to canonical form with hierarchy expansion.

        Handles platform hierarchy: ios → [ios, mobile, all]
        Handles environment hierarchy: prod → [prod, production, all]
        """
        if value is None:
            return []

        normalized = str(value).lower() if isinstance(value, str) else value

        # Platform normalization
        if key == "platform":
            return self.PLATFORM_HIERARCHY.get(normalized, [normalized, "all"])

        # Environment normalization
        if key == "environment":
            return self.ENVIRONMENT_HIERARCHY.get(normalized, [normalized, "all"])

        # Default: return as-is in list
        return [value] if not isinstance(value, list) else value

    def build_soft_filter_sql(
        self, filters: dict[str, Any], param_start: int = 1
    ) -> tuple[str, list[Any], int]:
        """
        Build SQL WHERE clause for soft (inclusive) filtering.

        Uses OR logic for hierarchical values to maximize recall.

        Returns:
            (where_clause, params, next_param_idx)
        """
        if not filters:
            return "", [], param_start

        conditions = []
        params = []
        param_idx = param_start

        for key, value in filters.items():
            normalized = self.normalize_filter_value(key, value)

            if not normalized:
                continue

            if len(normalized) == 1:
                conditions.append(f"metadata->>'{key}' = ${param_idx}")
                params.append(str(normalized[0]))
                param_idx += 1
            else:
                # OR condition for hierarchical values
                placeholders = ", ".join(f"${param_idx + i}" for i in range(len(normalized)))
                conditions.append(f"metadata->>'{key}' IN ({placeholders})")
                params.extend(str(v) for v in normalized)
                param_idx += len(normalized)

        where_clause = " AND ".join(conditions) if conditions else ""
        return where_clause, params, param_idx

    def apply_hard_filter(
        self,
        documents: list[dict[str, Any]],
        filters: dict[str, Any],
    ) -> FilterResult:
        """
        Apply strict filters post-retrieval with logging.

        Uses AND logic - document must match ALL filters.
        """
        if not filters:
            return FilterResult(
                documents=documents,
                phase1_count=len(documents),
                phase2_count=len(documents),
                filtered_out_count=0,
                fallback_triggered=False,
                fallback_reason=None,
            )

        filtered = []
        filter_breakdown: dict[str, int] = {k: 0 for k in filters}

        for doc in documents:
            metadata = doc.get("metadata", {})
            passes = True

            for key, expected in filters.items():
                actual = metadata.get(key)

                # Handle both single values and lists
                expected_list = expected if isinstance(expected, list) else [expected]

                # Normalize for comparison
                actual_normalized = str(actual).lower() if actual else None
                expected_normalized = [str(e).lower() for e in expected_list]

                if actual_normalized not in expected_normalized:
                    filter_breakdown[key] += 1
                    passes = False
                    break

            if passes:
                filtered.append(doc)

        filtered_out = len(documents) - len(filtered)

        if self.config.log_filtered_count and filtered_out > 0:
            logger.info(
                "hard_filter_applied",
                phase1_count=len(documents),
                phase2_count=len(filtered),
                filtered_out=filtered_out,
                breakdown=filter_breakdown,
            )

        return FilterResult(
            documents=filtered,
            phase1_count=len(documents),
            phase2_count=len(filtered),
            filtered_out_count=filtered_out,
            fallback_triggered=False,
            fallback_reason=None,
            filter_breakdown=filter_breakdown,
        )

    def apply_fallback(
        self,
        documents: list[dict[str, Any]],
        original_hard_filters: dict[str, Any],
    ) -> FilterResult:
        """
        Progressively remove filters until min_results is reached.

        Removes filters in order of least importance (tags first, then category, etc.)
        """
        current_filters = original_hard_filters.copy()

        # Order filters by importance (least important first to remove)
        removal_order = self.config.fallback_remove_filters

        for filter_to_remove in removal_order:
            if filter_to_remove not in current_filters:
                continue

            del current_filters[filter_to_remove]
            result = self.apply_hard_filter(documents, current_filters)

            if len(result.documents) >= self.config.min_results:
                logger.warning(
                    "fallback_triggered",
                    removed_filter=filter_to_remove,
                    result_count=len(result.documents),
                )
                return FilterResult(
                    documents=result.documents,
                    phase1_count=len(documents),
                    phase2_count=len(result.documents),
                    filtered_out_count=len(documents) - len(result.documents),
                    fallback_triggered=True,
                    fallback_reason=f"Removed filter: {filter_to_remove}",
                    filter_breakdown=result.filter_breakdown,
                )

        # If still no results, return all documents with warning
        logger.warning(
            "fallback_exhausted",
            returning_all=True,
            document_count=len(documents),
        )
        return FilterResult(
            documents=documents,
            phase1_count=len(documents),
            phase2_count=len(documents),
            filtered_out_count=0,
            fallback_triggered=True,
            fallback_reason="All filters removed - returning semantic matches only",
        )

    def filter_documents(
        self,
        documents: list[dict[str, Any]],
        soft_filters: dict[str, Any] | None = None,
        hard_filters: dict[str, Any] | None = None,
    ) -> FilterResult:
        """
        Apply two-phase filtering to documents.

        This is the main entry point for filtering.
        """
        hard = hard_filters or self.config.hard_filters

        # Phase 1: Soft filters (already applied during retrieval if using SQL)
        # Here we just track the count
        len(documents)

        # Phase 2: Hard filters
        result = self.apply_hard_filter(documents, hard)

        # Phase 3: Fallback if needed
        if self.config.enable_fallback and len(result.documents) < self.config.min_results:
            return self.apply_fallback(documents, hard)

        return result


# =============================================================================
# CONVENIENCE FUNCTIONS
# =============================================================================


def create_filter_config(
    platform: str | None = None,
    environment: str | None = None,
    doc_type: str | None = None,
    tags: list[str] | None = None,
    is_deprecated: bool | None = None,
    **extra_filters: Any,
) -> FilterConfig:
    """
    Create filter config with proper soft/hard separation.

    Soft filters (applied during search with OR logic):
        - platform, environment (hierarchical)

    Hard filters (applied post-search with AND logic):
        - doc_type, tags, is_deprecated, custom filters
    """
    soft: dict[str, Any] = {}
    hard: dict[str, Any] = {}

    # Soft filters (hierarchical)
    if platform:
        soft["platform"] = platform
    if environment:
        soft["environment"] = environment

    # Hard filters (strict)
    if doc_type:
        hard["doc_type"] = doc_type
    if tags:
        hard["tags"] = tags
    if is_deprecated is not None:
        hard["is_deprecated"] = is_deprecated

    hard.update(extra_filters)

    return FilterConfig(
        strategy=FilterStrategy.TWO_PHASE,
        soft_filters=soft,
        hard_filters=hard,
    )


def normalize_metadata_value(key: str, value: Any) -> Any:
    """
    Normalize a metadata value to canonical form during ingest.

    Use this when storing documents to ensure consistent filtering.
    """
    if value is None:
        return "all"

    normalized = str(value).lower().strip()

    # Platform normalization
    if key == "platform":
        mapping = {
            "iphone": "ios",
            "ipad": "ios",
            "macos": "desktop",
            "windows": "desktop",
            "linux": "desktop",
        }
        return mapping.get(normalized, normalized)

    # Environment normalization
    if key == "environment":
        mapping = {
            "production": "prod",
            "development": "dev",
            "stage": "staging",
            "test": "dev",
        }
        return mapping.get(normalized, normalized)

    return normalized
