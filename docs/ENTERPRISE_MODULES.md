# Enterprise Modules - Guia de Integra√ß√£o

## üìã Vis√£o Geral

**v5.5.0: M√≥dulos Integrados!**

Os m√≥dulos enterprise est√£o agora **totalmente integrados** no fluxo principal da aplica√ß√£o atrav√©s do `EnterpriseManager`.

**Status:** ‚úÖ Integrados e prontos para uso.

---

## üöÄ Quick Start

### Ativa√ß√£o via Settings

```bash
# .env ou vari√°veis de ambiente

# Phase 1: Essential (ativados por padr√£o)
APP_ENTERPRISE_ENABLE_INCIDENT_RESPONSE=true
APP_ENTERPRISE_ENABLE_AUTO_RECOVERY=true
APP_ENTERPRISE_ENABLE_RUNBOOKS=true

# Phase 2: Compliance
APP_ENTERPRISE_ENABLE_GDPR=true  # Ativar para EU
APP_ENTERPRISE_ENABLE_ENCRYPTED_AUDIT=true
APP_ENTERPRISE_ENABLE_SIEM=true
APP_ENTERPRISE_SIEM_ENDPOINT=https://your-siem.example.com
APP_ENTERPRISE_SIEM_API_KEY=your-api-key

# Phase 3: Observability
APP_ENTERPRISE_ENABLE_LOG_AGGREGATOR=true
APP_ENTERPRISE_ENABLE_ANOMALY_DETECTION=true
APP_ENTERPRISE_ANOMALY_SENSITIVITY=0.95

# Phase 4: Resilience (cuidado!)
APP_ENTERPRISE_ENABLE_CHAOS_ENGINEERING=false  # Apenas staging!
APP_ENTERPRISE_ENABLE_SERVICE_DISCOVERY=true
```

### Uso no C√≥digo

```python
from resync.core.enterprise import get_enterprise_manager

# Obter o manager (j√° inicializado no startup)
enterprise = await get_enterprise_manager()

# Reportar incidente
await enterprise.report_incident(
    title="Database connection timeout",
    description="Multiple connection failures detected",
    severity="high",
    category="infrastructure",
)

# Logar evento de audit
await enterprise.log_audit_event(
    action="user_login",
    user_id="user-123",
    resource="auth-service",
    details={"ip": "192.168.1.1", "method": "oauth"},
)

# Enviar evento de seguran√ßa (SIEM)
await enterprise.send_security_event(
    event_type="authentication_failure",
    severity="medium",
    source="api-gateway",
    details={"attempts": 5, "blocked": True},
)
```

### API Endpoints

```bash
# Status dos m√≥dulos enterprise
GET /api/v1/enterprise/status

# Health check
GET /api/v1/enterprise/health

# Incidents
POST /api/v1/enterprise/incidents
GET /api/v1/enterprise/incidents

# Audit
POST /api/v1/enterprise/audit
GET /api/v1/enterprise/audit/logs

# Security Events
POST /api/v1/enterprise/security/events

# GDPR
GET /api/v1/enterprise/gdpr/status
POST /api/v1/enterprise/gdpr/erasure-request

# Runbooks
GET /api/v1/enterprise/runbooks
POST /api/v1/enterprise/runbooks/{id}/execute

# Anomalies
GET /api/v1/enterprise/anomalies

# Service Discovery
GET /api/v1/enterprise/services
GET /api/v1/enterprise/services/{name}
```

---

## üö® Incident Response (`core/incident_response.py`)

**Linhas:** ~1,100 | **Prioridade:** Alta para produ√ß√£o

### O que faz
- Detec√ß√£o autom√°tica de incidentes
- Classifica√ß√£o por severidade (Critical, High, Medium, Low)
- Notifica√ß√µes autom√°ticas
- Escala√ß√£o inteligente
- Integra√ß√£o com runbooks

### Classes principais
```python
from resync.core.incident_response import (
    IncidentManager,
    IncidentSeverity,
    Incident,
    IncidentHandler,
)
```

### Como integrar
```python
# Em lifespan.py ou app_factory.py
from resync.core.incident_response import IncidentManager

incident_manager = IncidentManager()

# Registrar handlers
@incident_manager.on_incident(severity=IncidentSeverity.CRITICAL)
async def handle_critical(incident: Incident):
    await notify_oncall_team(incident)
```

---

## üî• Chaos Engineering (`core/chaos_engineering.py`)

**Linhas:** ~1,064 | **Prioridade:** M√©dia (testes de resili√™ncia)

### O que faz
- Inje√ß√£o de falhas controladas
- Testes de lat√™ncia
- Simula√ß√£o de quedas de servi√ßo
- Valida√ß√£o de circuit breakers
- Relat√≥rios de resili√™ncia

### Como integrar
```python
from resync.core.chaos_engineering import ChaosMonkey, ChaosExperiment

# Em ambiente de staging/test apenas!
chaos = ChaosMonkey(enabled=settings.CHAOS_ENABLED)

# Definir experimentos
experiment = ChaosExperiment(
    name="database_latency",
    target="postgresql",
    fault_type="latency",
    duration_seconds=30,
)

# Executar
await chaos.run_experiment(experiment)
```

---

## üá™üá∫ GDPR Compliance (`core/gdpr_compliance.py`)

**Linhas:** ~912 | **Prioridade:** Alta para Europa

### O que faz
- Rastreamento de consentimento
- Right to be forgotten (exclus√£o de dados)
- Data portability (exporta√ß√£o)
- Audit trail de acesso a dados pessoais
- Relat√≥rios de compliance

### Classes principais
```python
from resync.core.gdpr_compliance import (
    GDPRManager,
    ConsentRecord,
    DataSubjectRequest,
    PersonalDataInventory,
)
```

### Como integrar
```python
# Middleware para tracking
@app.middleware("http")
async def gdpr_middleware(request, call_next):
    gdpr = GDPRManager()
    await gdpr.log_data_access(
        user_id=request.user.id,
        data_type="personal",
        action="read",
    )
    return await call_next(request)
```

---

## üõ°Ô∏è SIEM Integrator (`core/siem_integrator.py`)

**Linhas:** ~884 | **Prioridade:** Alta para seguran√ßa

### O que faz
- Integra√ß√£o com Splunk, ELK, Azure Sentinel
- Envio de eventos de seguran√ßa
- Correla√ß√£o de eventos
- Alertas de seguran√ßa
- Formato CEF/LEEF

### Como integrar
```python
from resync.core.siem_integrator import SIEMIntegrator, SecurityEvent

siem = SIEMIntegrator(
    backend="splunk",
    endpoint=settings.SIEM_ENDPOINT,
    token=settings.SIEM_TOKEN,
)

# Enviar eventos
await siem.send_event(SecurityEvent(
    event_type="authentication_failure",
    severity="medium",
    source_ip=request.client.host,
))
```

---

## üìä Log Aggregator (`core/log_aggregator.py`)

**Linhas:** ~958 | **Prioridade:** M√©dia

### O que faz
- Agrega√ß√£o de logs de m√∫ltiplas fontes
- Parsing estruturado
- Compress√£o e rota√ß√£o
- Envio para backends (ELK, Loki, etc)
- M√©tricas de logs

### Como integrar
```python
from resync.core.log_aggregator import LogAggregator

aggregator = LogAggregator(
    backends=["elasticsearch", "loki"],
    batch_size=100,
    flush_interval=5,
)

# Substituir handler de logging
logging.getLogger().addHandler(aggregator.get_handler())
```

---

## üîç Service Discovery (`core/service_discovery.py`)

**Linhas:** ~818 | **Prioridade:** Alta para microservi√ßos

### O que faz
- Registro de servi√ßos
- Health checks autom√°ticos
- Load balancing
- Integra√ß√£o com Consul/etcd/Kubernetes
- DNS din√¢mico

### Como integrar
```python
from resync.core.service_discovery import ServiceRegistry

registry = ServiceRegistry(backend="consul")

# Registrar servi√ßo
await registry.register(
    name="resync-api",
    host=settings.SERVER_HOST,
    port=settings.SERVER_PORT,
    health_check="/health",
)

# Descobrir outros servi√ßos
rag_service = await registry.discover("rag-microservice")
```

---

## ü§ñ Anomaly Detector (`core/anomaly_detector.py`)

**Linhas:** ~749 | **Prioridade:** M√©dia

### O que faz
- Detec√ß√£o de anomalias com ML
- An√°lise de s√©ries temporais
- Alertas de comportamento anormal
- Baseline autom√°tico
- M√∫ltiplos algoritmos (IsolationForest, LSTM, etc)

### Como integrar
```python
from resync.core.anomaly_detector import AnomalyDetector

detector = AnomalyDetector(
    metrics=["response_time", "error_rate", "cpu_usage"],
    sensitivity=0.95,
)

# Background task
@repeat_every(seconds=60)
async def check_anomalies():
    anomalies = await detector.analyze()
    for anomaly in anomalies:
        await alert_team(anomaly)
```

---

## üîê Encrypted Audit (`core/encrypted_audit.py`)

**Linhas:** ~833 | **Prioridade:** Alta para compliance

### O que faz
- Audit logs criptografados (AES-256)
- Tamper-proof (hash chain)
- Rota√ß√£o de chaves
- Busca em logs criptografados
- Exporta√ß√£o para compliance

### Como integrar
```python
from resync.core.encrypted_audit import EncryptedAuditLogger

audit = EncryptedAuditLogger(
    encryption_key=settings.AUDIT_ENCRYPTION_KEY,
    storage_backend="postgresql",
)

# Registrar eventos
await audit.log(
    action="data_export",
    user_id=user.id,
    resource="customer_data",
    details={"records": 1500},
)
```

---

## ‚ö° Database Optimizer (`core/database_optimizer.py`)

**Linhas:** ~571 | **Prioridade:** M√©dia

### O que faz
- An√°lise de queries lentas
- Sugest√£o de √≠ndices
- Query rewriting autom√°tico
- Cache de queries frequentes
- Monitoramento de performance

### Como integrar
```python
from resync.core.database_optimizer import DatabaseOptimizer

optimizer = DatabaseOptimizer(database_url=settings.DATABASE_URL)

# An√°lise peri√≥dica
@repeat_every(hours=1)
async def optimize_database():
    suggestions = await optimizer.analyze()
    for suggestion in suggestions:
        logger.info(f"Optimization: {suggestion}")
```

---

## üîÑ Auto Recovery (`core/auto_recovery.py`)

**Linhas:** ~377 | **Prioridade:** Alta para produ√ß√£o

### O que faz
- Recupera√ß√£o autom√°tica de falhas
- Restart de servi√ßos
- Limpeza de recursos √≥rf√£os
- Self-healing

### Como integrar
```python
from resync.core.auto_recovery import AutoRecovery

recovery = AutoRecovery()

# Registrar handlers de recupera√ß√£o
@recovery.on_failure("database")
async def recover_database():
    await reconnect_database()
    await clear_connection_pool()
```

---

## üìñ Runbooks (`core/runbooks.py`)

**Linhas:** ~377 | **Prioridade:** M√©dia

### O que faz
- Automa√ß√£o de procedimentos operacionais
- Playbooks para incidentes
- Execu√ß√£o de steps automatizados
- Integra√ß√£o com incident response

### Classes principais
```python
from resync.core.runbooks import (
    IncidentRunbook,
    TWSConnectionFailureRunbook,
    DatabaseFailureRunbook,
)
```

### Como integrar
```python
# Executar runbook automaticamente
runbook = TWSConnectionFailureRunbook()
await runbook.execute(incident)
```

---

## üöÄ Roadmap de Integra√ß√£o Sugerido

### Fase 1 - Essencial para Produ√ß√£o
1. ‚úÖ `incident_response.py` - Resposta a incidentes
2. ‚úÖ `auto_recovery.py` - Self-healing
3. ‚úÖ `runbooks.py` - Automa√ß√£o operacional

### Fase 2 - Compliance
4. ‚úÖ `gdpr_compliance.py` - GDPR (se Europa)
5. ‚úÖ `encrypted_audit.py` - Audit criptografado
6. ‚úÖ `siem_integrator.py` - Seguran√ßa

### Fase 3 - Observabilidade
7. ‚úÖ `log_aggregator.py` - Logs centralizados
8. ‚úÖ `anomaly_detector.py` - Detec√ß√£o de anomalias
9. ‚úÖ `database_optimizer.py` - Performance DB

### Fase 4 - Resili√™ncia
10. ‚úÖ `chaos_engineering.py` - Testes de caos
11. ‚úÖ `service_discovery.py` - Microservi√ßos

---

## üìù Notas

- Todos os m√≥dulos est√£o **implementados** mas com **0 imports** atuais
- Requerem configura√ß√£o adicional (env vars, backends)
- Alguns requerem depend√™ncias extras (ML, integrations)
- Documenta√ß√£o inline dispon√≠vel em cada arquivo

---

# Utility Modules - M√≥dulos Utilit√°rios

## üìã Vis√£o Geral

Estes m√≥dulos utilit√°rios complementam os enterprise modules e fornecem funcionalidades de suporte.

---

## üìä Benchmarking (`core/benchmarking.py`)

**Linhas:** ~270 | **Uso:** Testes de performance

### O que faz
- Benchmarks de endpoints
- M√©tricas de lat√™ncia
- Compara√ß√£o de performance
- Relat√≥rios automatizados

```python
from resync.core.benchmarking import Benchmark, BenchmarkResult

benchmark = Benchmark()
result = await benchmark.run("/api/query", iterations=100)
print(f"P95 latency: {result.p95_ms}ms")
```

---

## ‚è±Ô∏è Task Manager (`core/task_manager.py`)

**Linhas:** ~316 | **Uso:** Background jobs

### O que faz
- Gerenciamento de tarefas ass√≠ncronas
- Scheduling de jobs
- Retry autom√°tico
- Monitoramento de tasks

```python
from resync.core.task_manager import TaskManager

manager = TaskManager()

@manager.task(retry=3, timeout=60)
async def process_data(data):
    ...
```

---

## üîÑ Config Hot Reload (`core/config_hot_reload.py`)

**Linhas:** ~297 | **Uso:** Reload de config sem restart

### O que faz
- Monitoramento de arquivos de config
- Reload autom√°tico
- Valida√ß√£o de config
- Notifica√ß√µes de mudan√ßa

```python
from resync.core.config_hot_reload import ConfigHotReload

reloader = ConfigHotReload(config_path=".env")
reloader.on_change(lambda: logger.info("Config updated!"))
```

---

## üëÄ Config Watcher (`core/config_watcher.py`)

**Linhas:** ~66 | **Uso:** Complementa hot reload

### O que faz
- Watch de arquivos de configura√ß√£o
- Integra√ß√£o com container DI

---

## üîê Encryption Service (`core/encryption_service.py`)

**Linhas:** ~85 | **Uso:** Criptografia de dados

### O que faz
- Criptografia AES-256
- Hashing seguro
- Gera√ß√£o de tokens
- Key management

```python
from resync.core.encryption_service import EncryptionService

crypto = EncryptionService(key=settings.ENCRYPTION_KEY)
encrypted = crypto.encrypt("sensitive data")
decrypted = crypto.decrypt(encrypted)
```

---

## üîÑ Lifecycle Manager (`core/lifecycle.py`)

**Linhas:** ~198 | **Uso:** Startup/shutdown

### O que faz
- Gerenciamento de ciclo de vida
- Cleanup de recursos
- Graceful shutdown
- Health checks de recursos

```python
from resync.core.lifecycle import ResourceManager

lifecycle = ResourceManager()

@lifecycle.on_startup
async def init_database():
    ...

@lifecycle.on_shutdown
async def cleanup():
    ...
```

---

## üìà Performance Tracker (`core/performance_tracker.py`)

**Linhas:** ~381 | **Uso:** M√©tricas de performance

### O que faz
- Tracking de m√©tricas
- Histogramas de lat√™ncia
- Alertas de degrada√ß√£o
- Dashboards

---

## ‚ö° Validation Optimizer (`core/validation_optimizer.py`)

**Linhas:** ~338 | **Uso:** Otimiza√ß√£o de valida√ß√µes

### O que faz
- Cache de valida√ß√µes
- Valida√ß√£o lazy
- Otimiza√ß√£o de schemas Pydantic

---

## üîÆ Predictive Analysis (`core/predictive_analysis.py`, `core/predictive_analyzer.py`)

**Linhas:** ~480 | **Uso:** ML/Forecasting

### O que faz
- An√°lise preditiva
- Forecasting de m√©tricas
- Detec√ß√£o de tend√™ncias
- Alertas proativos

---

## üìù Logging Utils (`core/logging_utils.py`)

**Linhas:** ~162 | **Uso:** Helpers de logging

### O que faz
- Reda√ß√£o de secrets em logs
- Formata√ß√£o estruturada
- Correlation IDs
- Log sampling

---

## üë§ User Behavior (`core/user_behavior.py`)

**Linhas:** ~125 | **Uso:** Analytics

### O que faz
- An√°lise de comportamento do usu√°rio
- Padr√µes de uso
- M√©tricas de engagement
