# ‚öôÔ∏è GraphRAG Configuration Guide - Optimized for TWS

## üéØ Configura√ß√µes Otimizadas (v5.9.8 Final)

### Valores Padr√£o (Ajustados para Ambiente Real)

```python
# resync/core/event_driven_discovery.py

class DiscoveryConfig:
    # Budget controls - CONSERVADOR para produ√ß√£o
    MAX_DISCOVERIES_PER_DAY = 5      # ‚úÖ Realista: 5 novos patterns/dia
    MAX_DISCOVERIES_PER_HOUR = 2     # ‚úÖ Previne spikes
    
    # Cache TTL - Depend√™ncias TWS s√£o EST√ÅTICAS!
    DISCOVERY_CACHE_DAYS = 90        # ‚úÖ 3 meses (raramente mudam)
    
    # Triggers - SELETIVO
    MIN_FAILURES_TO_TRIGGER = 3      # ‚úÖ Espera 3 falhas (n√£o 2)
    
    # Critical jobs - CUSTOMIZAR!
    CRITICAL_JOBS = {
        "PAYROLL_NIGHTLY",
        "BACKUP_DB",
        # Adicione seus jobs aqui
    }
```

---

## üìä Compara√ß√£o: Valores Iniciais vs Otimizados

| Configura√ß√£o | Inicial (Ruim) | Otimizado (Bom) | Motivo |
|--------------|----------------|-----------------|--------|
| **MAX_DISCOVERIES_PER_DAY** | 50 | **5** | Depend√™ncias TWS raramente mudam |
| **MAX_DISCOVERIES_PER_HOUR** | 10 | **2** | Previne waste em caso de spike |
| **CACHE_DAYS** | 7 | **90** | Jobs batch t√™m depend√™ncias fixas |
| **MIN_FAILURES** | 2 | **3** | Mais conservador, menos false positives |

---

## üí° Racioc√≠nio por tr√°s dos valores

### 1. Cache de 90 dias (n√£o 7)

**Por qu√™?**
```
Ambiente TWS:
- Depend√™ncias definidas no PLANO de produ√ß√£o
- Plano raramente muda (talvez 1x/m√™s ou menos)
- Descobrir "PAYROLL depende de BACKUP_DB" NUNCA muda
- Cache de 7 dias = re-descobrir a cada semana = DESPERD√çCIO!

Cache de 90 dias:
- Descoberto 1 vez ‚Üí v√°lido por 3 meses
- S√≥ re-descobre se:
  a) Cache expirou (90 dias), OU
  b) Invalidado manualmente (plano mudou)
```

**Quando invalidar cache manualmente:**
```bash
# Plano TWS mudou (nova depend√™ncia, job removido, etc)
curl -X POST http://localhost:8000/api/admin/graphrag/cache/invalidate \
  -H "Content-Type: application/json" \
  -d '{"job_name": null}'  # null = invalidar tudo

# Ou job espec√≠fico:
-d '{"job_name": "PAYROLL_NIGHTLY"}'
```

---

### 2. MAX_DISCOVERIES_PER_DAY = 5 (n√£o 50)

**Por qu√™?**
```
C√°lculo realista:

Jobs cr√≠ticos: 50
Discoveries necess√°rias: 50 (1x cada)
Frequ√™ncia: 1x por per√≠odo de cache (90 dias)

Discoveries/dia = 50 jobs √∑ 90 dias = 0.5/dia

Na pr√°tica:
- Novos jobs adicionados: ~1-2/m√™s
- Erros novos descobertos: ~2-3/semana
- Total realista: ~1-2 discoveries/dia

Configurar 5/dia:
- Margem de seguran√ßa 2.5x-5x
- Previne waste se tiver spike de falhas
- Ainda permite crescimento
```

**Se atingir limite:**
```bash
# Ver estat√≠sticas
curl http://localhost:8000/api/admin/graphrag/stats

# Resposta:
{
  "discoveries_today": 5,        # Limite atingido!
  "budget_daily": 5,
  "discoveries_this_hour": 1
}

# Se realmente precisa mais, aumentar:
# resync/core/event_driven_discovery.py
MAX_DISCOVERIES_PER_DAY = 10  # Ajustar se necess√°rio
```

---

### 3. MAX_DISCOVERIES_PER_HOUR = 2 (n√£o 10)

**Por qu√™?**
```
Cen√°rio problem√°tico:
- Falha em cascata (10 jobs falham simultaneamente)
- Sem limite hor√°rio: 10 discoveries imediatas
- 10 √ó 2s = 20s processamento + 10 LLM calls

Com limite = 2:
- Primeiros 2 jobs: descobertos imediatamente
- Pr√≥ximos 8 jobs: pr√≥xima hora (se ainda falhando)
- Previne overload moment√¢neo

L√≥gica:
- Falha cascata geralmente tem MESMA root cause
- Descobrir 2 jobs j√° captura o pattern
- Demais jobs provavelmente t√™m mesma depend√™ncia
```

---

### 4. MIN_FAILURES_TO_TRIGGER = 3 (n√£o 2)

**Por qu√™?**
```
Falha isolada vs Pattern:

Falha 1x: Pode ser glitch (rede, timeout pontual)
Falha 2x: Pode ser coincid√™ncia
Falha 3x: PATTERN! Vale a pena descobrir

Esperar 3 falhas:
- Reduz false positives
- Economiza LLM calls desnecess√°rias
- Ainda captura patterns reais
```

---

## üîß Customiza√ß√£o por Ambiente

### Ambiente PEQUENO (< 100 jobs)

```python
class DiscoveryConfig:
    MAX_DISCOVERIES_PER_DAY = 3      # Menos jobs = menos discoveries
    MAX_DISCOVERIES_PER_HOUR = 1     # Conservador
    DISCOVERY_CACHE_DAYS = 180       # 6 meses (ambiente est√°vel)
    MIN_FAILURES_TO_TRIGGER = 2      # Pode ser 2 (menos volume)
```

---

### Ambiente M√âDIO (100-500 jobs)

```python
class DiscoveryConfig:
    MAX_DISCOVERIES_PER_DAY = 5      # ‚úÖ Padr√£o (bom para maioria)
    MAX_DISCOVERIES_PER_HOUR = 2     # ‚úÖ Padr√£o
    DISCOVERY_CACHE_DAYS = 90        # ‚úÖ Padr√£o
    MIN_FAILURES_TO_TRIGGER = 3      # ‚úÖ Padr√£o
```

---

### Ambiente GRANDE (> 500 jobs)

```python
class DiscoveryConfig:
    MAX_DISCOVERIES_PER_DAY = 10     # Mais jobs = mais varia√ß√£o
    MAX_DISCOVERIES_PER_HOUR = 3     # Permite mais concorr√™ncia
    DISCOVERY_CACHE_DAYS = 60        # 2 meses (plano muda mais)
    MIN_FAILURES_TO_TRIGGER = 3      # Manter conservador
```

---

### Ambiente DIN√ÇMICO (jobs novos frequentes)

```python
class DiscoveryConfig:
    MAX_DISCOVERIES_PER_DAY = 10     # Permite novos jobs
    MAX_DISCOVERIES_PER_HOUR = 3
    DISCOVERY_CACHE_DAYS = 30        # 1 m√™s (ambiente muda muito)
    MIN_FAILURES_TO_TRIGGER = 2      # Descobrir r√°pido
```

---

## üõ†Ô∏è Admin Endpoints

### 1. Ver Estat√≠sticas

```bash
GET /api/admin/graphrag/stats

# Resposta:
{
  "enabled": true,
  "discovery": {
    "discoveries_today": 2,
    "discoveries_this_hour": 0,
    "budget_daily": 5,
    "budget_hourly": 2,
    "critical_jobs_count": 4,
    "cache_ttl_days": 90,
    "last_reset": "2024-12-25T00:00:00"
  }
}
```

---

### 2. Invalidar Cache (Ap√≥s mudan√ßas no plano TWS)

```bash
# Invalidar tudo
POST /api/admin/graphrag/cache/invalidate
Content-Type: application/json

{"job_name": null}

# Resposta:
{
  "status": "success",
  "cache_entries_deleted": 15,
  "job_name": "all"
}

# Invalidar job espec√≠fico
{"job_name": "PAYROLL_NIGHTLY"}
```

**Quando usar:**
- ‚úÖ Adicionou novo job ao plano TWS
- ‚úÖ Mudou depend√™ncias entre jobs
- ‚úÖ Removeu job do ambiente
- ‚úÖ Migrou jobs entre workstations
- ‚ùå Job falhou (cache v√°lido, deixar expirar naturalmente)

---

### 3. Ver Configura√ß√£o Atual

```bash
GET /api/admin/graphrag/config

# Resposta:
{
  "budget": {
    "max_discoveries_per_day": 5,
    "max_discoveries_per_hour": 2
  },
  "cache": {
    "ttl_days": 90
  },
  "triggers": {
    "discover_on_new_error": true,
    "discover_on_recurring_failure": true,
    "min_failures_to_trigger": 3
  },
  "critical_jobs": [
    "PAYROLL_NIGHTLY",
    "BACKUP_DB",
    "ETL_CUSTOMER",
    "REPORT_SALES"
  ]
}
```

---

### 4. For√ßar Discovery Manual (Testing)

```bash
# For√ßar discovery de job espec√≠fico (bypass filters)
POST /api/admin/graphrag/discover
Content-Type: application/json

{
  "job_name": "NEW_CRITICAL_JOB",
  "force": true
}

# Resposta:
{
  "status": "triggered",
  "job_name": "NEW_CRITICAL_JOB",
  "message": "Discovery started in background (forced)"
}
```

**Quando usar:**
- ‚úÖ Testing ap√≥s adicionar novo job
- ‚úÖ For√ßar re-discovery ap√≥s corrigir plano
- ‚úÖ Validar que discovery funciona
- ‚ùå Rotina operacional (deixar autom√°tico)

---

## üí∞ Compara√ß√£o de Custos

### Configura√ß√£o Inicial (Ruim)

```
MAX_DISCOVERIES_PER_DAY = 50
CACHE_DAYS = 7

Cen√°rio:
- 50 jobs cr√≠ticos
- Cache expira a cada 7 dias
- Re-discovery cont√≠nua

Discoveries/m√™s:
50 jobs √ó (30 dias √∑ 7 dias) = 214 discoveries/m√™s

Custo (Ollama local):
- API: $0 (local)
- CPU/RAM: Alto (214 LLM calls/m√™s)
- Lat√™ncia acumulada: 214 √ó 2s = 428s/m√™s processamento

Custo (OpenAI):
214 √ó $0.003 = $0.64/m√™s
```

---

### Configura√ß√£o Otimizada (Boa)

```
MAX_DISCOVERIES_PER_DAY = 5
CACHE_DAYS = 90

Cen√°rio:
- 50 jobs cr√≠ticos
- Cache v√°lido por 90 dias
- Discovery apenas quando necess√°rio

Discoveries/m√™s:
50 jobs √ó (30 dias √∑ 90 dias) = 16 discoveries/m√™s
+ ~5 novos patterns = ~20 discoveries/m√™s

Custo (Ollama local):
- API: $0 (local)
- CPU/RAM: Baixo (20 LLM calls/m√™s)
- Lat√™ncia acumulada: 20 √ó 2s = 40s/m√™s processamento

Custo (OpenAI):
20 √ó $0.003 = $0.06/m√™s

ECONOMIA: 91% menos discoveries!
```

---

## üìà Monitoramento Recomendado

### Dashboard Metrics

```python
# M√©tricas importantes para monitorar:

1. discoveries_today / budget_daily
   ‚Üí Se ‚â• 80%: Considerar aumentar budget

2. cache_hit_rate
   ‚Üí Esperado: > 95% (com cache de 90 dias)
   ‚Üí Se < 90%: Cache muito curto ou plano mudando muito

3. avg_failures_before_discovery
   ‚Üí Esperado: ~3 (igual MIN_FAILURES_TO_TRIGGER)
   ‚Üí Se < 3: Talvez relaxar trigger

4. discoveries_per_critical_job
   ‚Üí Esperado: ~1-2 (durante vida do cache)
   ‚Üí Se > 5: Job muito inst√°vel ou cache muito curto
```

---

## ‚úÖ Checklist de Deploy

Antes de implantar em produ√ß√£o:

```
‚ñ° Customizar CRITICAL_JOBS com seus jobs reais
‚ñ° Ajustar budgets para seu tamanho de ambiente
‚ñ° Configurar cache_ttl_days baseado em frequ√™ncia de mudan√ßas
‚ñ° Testar invalida√ß√£o de cache manual
‚ñ° Configurar monitoramento de /api/admin/graphrag/stats
‚ñ° Documentar quando invalidar cache (mudan√ßas de plano)
‚ñ° Treinar equipe em uso de admin endpoints
```

---

## üéØ Resumo Executivo

| Config | Valor Otimizado | Economia vs Inicial |
|--------|-----------------|---------------------|
| **Cache TTL** | 90 dias | 12.8x menos re-discoveries |
| **Daily Budget** | 5/dia | 10x mais conservador |
| **Hourly Budget** | 2/hora | 5x mais conservador |
| **Min Failures** | 3 | 50% mais seletivo |

**Resultado:**
- 91% menos LLM calls
- Cache hit rate > 95%
- Custo: $0.06/m√™s (vs $0.64/m√™s)
- Invalida√ß√£o manual quando plano muda
- Admin endpoints para controle total

**Configura√ß√£o otimizada para ambiente TWS real! üéØ**
