# RESYNC v5.3.22 - Environment Configuration
# Copy this file to .env and fill in the values
# 
# SECURITY: Never commit .env files with real credentials to version control
#
# PRODUCTION CHECKLIST:
# ✅ Set ENVIRONMENT=production
# ✅ Generate secure SECRET_KEY (32+ characters)
# ✅ Configure CORS_ALLOW_ORIGINS with exact domains (no wildcards)
# ✅ Set DATABASE_SSL_MODE=require
# ✅ Set ENFORCE_HTTPS=true (when behind TLS proxy)
# ✅ Set LOG_LEVEL=INFO or WARNING (not DEBUG)
# ✅ Review rate limits for your traffic patterns

# =============================================================================
# CRITICAL - MUST BE SET FOR PRODUCTION
# =============================================================================

# Environment (development, staging, production)
ENVIRONMENT=development

# JWT/Session Security (REQUIRED IN PRODUCTION)
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=

# Admin Credentials (REQUIRED)
ADMIN_USERNAME=admin
ADMIN_PASSWORD=

# =============================================================================
# DATABASE (REQUIRED)
# =============================================================================

# Full connection URL (preferred)
DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/resync

# Or individual settings:
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=resync
DATABASE_USER=resync
DATABASE_PASSWORD=

# Connection Pool Settings (adjusted for single VM)
# Docker/K8s: increase based on available resources
DATABASE_POOL_SIZE=5
DATABASE_MAX_OVERFLOW=10
DATABASE_POOL_TIMEOUT=30
DATABASE_POOL_RECYCLE=1800
# SSL Mode: prefer (default), require (production), verify-ca, verify-full
DATABASE_SSL_MODE=require

# =============================================================================
# TWS Integration
# =============================================================================

TWS_HOST=localhost
TWS_PORT=31111
TWS_USERNAME=
TWS_PASSWORD=
TWS_ENGINE_NAME=
TWS_ENGINE_OWNER=

# =============================================================================
# Redis (Optional - required for multi-worker deployments)
# =============================================================================

# Basic Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_URL=redis://localhost:6379
RESYNC_DISABLE_REDIS=false

# Connection Pool Settings
REDIS_POOL_MIN=5
REDIS_POOL_MAX=20
REDIS_SOCKET_TIMEOUT=5.0
REDIS_CONNECT_TIMEOUT=5.0
REDIS_HEALTH_INTERVAL=30

# =============================================================================
# Semantic Cache (v5.3.16) - LLM Response Caching
# =============================================================================
# Reduces API costs by 60-70% by caching semantically similar queries
# Requires: pip install sentence-transformers

# Cache threshold (0.1-0.5): Lower = more strict, fewer false positives
# Recommended: 0.25 for balanced performance
SEMANTIC_CACHE_THRESHOLD=0.25

# Default TTL in seconds (86400 = 24 hours)
SEMANTIC_CACHE_TTL=86400

# Maximum cache entries before LRU eviction
SEMANTIC_CACHE_MAX_ENTRIES=100000

# Embedding model (optional - uses all-MiniLM-L6-v2 by default)
# SEMANTIC_CACHE_EMBEDDING_MODEL=all-MiniLM-L6-v2

# =============================================================================
# AI/LLM Configuration
# =============================================================================

# OpenAI (usado como fallback quando Ollama timeout)
OPENAI_API_KEY=

# Azure OpenAI
AZURE_OPENAI_API_KEY=
AZURE_API_KEY=

# Other providers (optional)
COHERE_API_KEY=
VOYAGE_API_KEY=
HUGGINGFACE_API_KEY=
NVIDIA_API_KEY=

# =============================================================================
# Ollama - Local LLM (v5.2.3.21)
# =============================================================================
# CPU-only inference for zero-cost LLM operations
# Instale: https://ollama.com/download
# Baixe modelo: ollama pull qwen2.5:3b

# Habilitar Ollama como provider primário
OLLAMA_ENABLED=true

# URL do servidor Ollama
OLLAMA_BASE_URL=http://localhost:11434

# Modelo padrão (sem prefixo ollama/)
OLLAMA_MODEL=qwen2.5:3b

# Tamanho da janela de contexto (4096 recomendado para 16GB RAM)
OLLAMA_NUM_CTX=4096

# Threads CPU (usar = núcleos físicos, não hyperthreads)
OLLAMA_NUM_THREAD=4

# Timeout agressivo para fallback rápido ao cloud (segundos)
OLLAMA_TIMEOUT=8.0

# Modelo LLM padrão (com prefixo para LiteLLM)
LLM_MODEL=ollama/qwen2.5:3b

# Timeout geral do LLM
LLM_TIMEOUT=8.0

# Modelo de fallback quando Ollama falha
LLM_FALLBACK_MODEL=gpt-4o-mini

# =============================================================================
# Hybrid Retriever - BM25 + Vector Search (v5.2.3.22)
# =============================================================================
# Otimiza retrieval para domínio TWS combinando busca exata e semântica

# Peso base da busca vetorial (semântica) - 0.0 a 1.0
HYBRID_VECTOR_WEIGHT=0.5

# Peso base da busca BM25 (keywords/exato) - 0.0 a 1.0
HYBRID_BM25_WEIGHT=0.5

# Ajuste automático de pesos baseado no tipo de query
# true = detecta patterns TWS (job codes, RC codes) e ajusta pesos automaticamente
# false = usa sempre os pesos fixos acima
HYBRID_AUTO_WEIGHT=true

# v5.2.3.23: Field Boost Weights para BM25
# Maior valor = maior importância no ranking
# Valores recomendados para domínio TWS:
HYBRID_BOOST_JOB_NAME=4.0       # Nome do job (crítico para match exato)
HYBRID_BOOST_ERROR_CODE=3.5     # Códigos de erro (RC, ABEND)
HYBRID_BOOST_WORKSTATION=3.0    # Workstation/servidor
HYBRID_BOOST_JOB_STREAM=2.5     # Job stream/schedule
HYBRID_BOOST_MESSAGE_ID=2.5     # IDs de mensagem (EQQQ...)
HYBRID_BOOST_RESOURCE=2.0       # Recursos TWS
HYBRID_BOOST_TITLE=1.5          # Título do documento
HYBRID_BOOST_CONTENT=1.0        # Conteúdo geral (baseline)

# =============================================================================
# Observability (Optional)
# =============================================================================

# LangFuse
LANGFUSE_ENABLED=false
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=
LANGFUSE_HOST=https://cloud.langfuse.com
LANGFUSE_SAMPLE_RATE=1.0

# Evidently AI Monitoring
EVIDENTLY_ENABLED=false
EVIDENTLY_REPORTS_DIR=./reports/evidently

# =============================================================================
# Application Settings
# =============================================================================

LOG_LEVEL=INFO

# Server Configuration
# ⚠️  SECURITY: Use 127.0.0.1 in production behind a reverse proxy (nginx/traefik)
# Docker/K8s: Set to 0.0.0.0 only when container networking handles isolation
SERVER_HOST=127.0.0.1
SERVER_PORT=8000

# Worker Configuration (for gunicorn/uvicorn multi-worker deployments)
# Formula: workers = (2 x CPU cores) + 1
WORKERS=1
WORKER_CLASS=uvicorn.workers.UvicornWorker
WORKER_TIMEOUT=120
GRACEFUL_TIMEOUT=30

# Security
ENCRYPTION_KEY=
JWT_ALGORITHM=HS256

# HTTPS/TLS Security (set True when behind TLS-terminating proxy)
ENFORCE_HTTPS=false
SSL_REDIRECT=false

# Session Security
SESSION_TIMEOUT_MINUTES=30
SESSION_SECURE_COOKIE=true
SESSION_HTTP_ONLY=true
SESSION_SAME_SITE=lax

# Compression
COMPRESSION_ENABLED=true
COMPRESSION_MINIMUM_SIZE=500
COMPRESSION_LEVEL=6

# Rate Limiting (per minute)
# Adjust based on expected traffic and security requirements
RATE_LIMIT_PUBLIC_PER_MINUTE=60
RATE_LIMIT_AUTHENTICATED_PER_MINUTE=300
RATE_LIMIT_CRITICAL_PER_MINUTE=10

# CORS (comma-separated list of allowed origins)
# ⚠️  SECURITY: Never use "*" in production!
# Development: http://localhost:3000,http://localhost:8080
# Production: https://yourdomain.com,https://app.yourdomain.com
CORS_ALLOW_ORIGINS=http://localhost:3000,http://localhost:8080

# =============================================================================
# RAG Configuration
# =============================================================================

RAG_COLLECTION=default
RAG_USE_MOCK=false
RAG_UPLOAD_DIR=./uploads
RAG_SNAPSHOT_DIR=~/.resync/rag_snapshots

# Embedding
EMBEDDING_MODEL=text-embedding-ada-002
EMBEDDING_DIMENSION=1536
EMBEDDING_BATCH_SIZE=100

# HNSW Index Parameters
RAG_HNSW_M=16
RAG_HNSW_EF_CONSTRUCTION=64
RAG_EF_SEARCH_BASE=40
RAG_EF_SEARCH_MAX=200
RAG_MAX_TOPK=100
RAG_MAX_NEIGHBORS=50

# =============================================================================
# Backup Configuration (v5.3.22 - Enhanced)
# =============================================================================

BACKUP_ENABLED=true
BACKUP_DIR=./backups
BACKUP_RETENTION_DAYS=30
# Cron format: minute hour day month weekday
BACKUP_SCHEDULE_CRON=0 2 * * *
BACKUP_INCLUDE_DATABASE=true
BACKUP_INCLUDE_UPLOADS=true
BACKUP_INCLUDE_CONFIG=true
BACKUP_COMPRESSION=true

# =============================================================================
# Health Check Configuration
# =============================================================================

HEALTH_SANITIZE_CONNECTIONS=true
HEALTH_SANITIZE_PATHS=true
HEALTH_SANITIZE_SQL=true
HEALTH_LOG_FULL_ERRORS=false
HEALTH_INCLUDE_STACK_TRACES=false
HEALTH_ERROR_DETAIL_LEVEL=minimal
HEALTH_ERROR_ID_LENGTH=8

# =============================================================================
# RAG Cross-Encoder Reranking (v5.3.17)
# =============================================================================
# Enable cross-encoder for two-stage retrieval (recommended for production)
RAG_CROSS_ENCODER_ON=true

# Cross-encoder model (options: BAAI/bge-reranker-small, BAAI/bge-reranker-base)
# small: ~150MB RAM, good balance of speed/accuracy
# base: ~1.1GB RAM, better accuracy, slower
RAG_CROSS_ENCODER_MODEL=BAAI/bge-reranker-small

# Number of documents to return after reranking
RAG_CROSS_ENCODER_TOP_K=5

# Minimum score threshold (0-1) to keep documents
RAG_CROSS_ENCODER_THRESHOLD=0.3
